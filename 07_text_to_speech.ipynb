{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12ca1c34",
   "metadata": {},
   "source": [
    "# Part 1: Rule‑Based G2P Conversion and Duration Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9da3250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_g2p(word):\n",
    "    word = word.lower()\n",
    "    phoneme_sequence = []\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if i < len(word) - 1 and word[i:i+2] == \"th\":\n",
    "            phoneme_sequence.append(\"DH\")\n",
    "            i += 2\n",
    "        elif i < len(word) - 1 and word[i] == \"c\":\n",
    "            if word[i+1] in [\"e\", \"i\", \"y\"]:\n",
    "                phoneme_sequence.append(\"S\")\n",
    "            else:\n",
    "                phoneme_sequence.append(\"K\")\n",
    "            i += 1\n",
    "        elif i < len(word) - 1 and word[i] == word[i+1] and word[i].isalpha():\n",
    "            phoneme_sequence.append(word[i].upper())\n",
    "            i += 2\n",
    "        else:\n",
    "            phoneme_sequence.append(word[i].upper())\n",
    "            i += 1\n",
    "\n",
    "    if word == \"the\":\n",
    "        phoneme_sequence = [\"DH\", \"AH\"]\n",
    "\n",
    "    return phoneme_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c09d833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: cat -> Phonemes: K-A-T\n",
      "Word: cent -> Phonemes: S-E-N-T\n",
      "Word: apple -> Phonemes: A-P-L-E\n",
      "Word: the -> Phonemes: DH-AH\n",
      "Word: book -> Phonemes: B-O-K\n",
      "Word: tree -> Phonemes: T-R-E\n"
     ]
    }
   ],
   "source": [
    "words1 = [\"cat\", \"cent\", \"apple\", \"the\", \"book\", \"tree\"]\n",
    "for w in words1:\n",
    "    phonemes = simple_g2p(w)\n",
    "    print(f\"Word: {w} -> Phonemes: {'-'.join(phonemes)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494c2ea",
   "metadata": {},
   "source": [
    " Part 2: Basic Prosodic Modeling- Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3d2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_g2p_with_duration(word):\n",
    "    \n",
    "    word = word.lower()\n",
    "    phoneme_sequence = []\n",
    "    durations = []\n",
    "    vowels = \"aeiou\"\n",
    "    base_vowel_duration = 100   \n",
    "    base_consonant_duration = 50 \n",
    "    final_syllable_duration_increase = 20  \n",
    "\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if i < len(word) - 1 and word[i:i+2] == \"th\":\n",
    "            phoneme = \"DH\"\n",
    "            i += 2\n",
    "        elif i < len(word) - 1 and word[i] == \"c\":\n",
    "            if word[i+1] in vowels:\n",
    "                phoneme = \"S\"\n",
    "            else:\n",
    "                phoneme = \"K\"\n",
    "            i += 1\n",
    "        elif i < len(word) - 1 and word[i] == word[i+1] and word[i].isalpha():\n",
    "            phoneme = word[i].upper()\n",
    "            i += 2\n",
    "        else:\n",
    "            phoneme = word[i].upper()\n",
    "            i += 1\n",
    "\n",
    "        phoneme_sequence.append(phoneme)\n",
    "\n",
    "        if phoneme.lower() in vowels:\n",
    "            durations.append(base_vowel_duration)\n",
    "        else:\n",
    "            durations.append(base_consonant_duration)\n",
    "\n",
    "    if durations:\n",
    "        durations[-1] += final_syllable_duration_increase\n",
    "\n",
    "    if word == \"the\":\n",
    "        phoneme_sequence = [\"DH\", \"AH\"]\n",
    "        durations = [\n",
    "            base_consonant_duration,\n",
    "            base_vowel_duration + final_syllable_duration_increase\n",
    "        ]\n",
    "\n",
    "    return phoneme_sequence, durations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2eb0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: cat -> Phonemes: K-A-T\n",
      "Word: cent -> Phonemes: S-E-N-T\n",
      "Word: apple -> Phonemes: A-P-L-E\n",
      "Word: the -> Phonemes: DH-AH\n",
      "Word: book -> Phonemes: B-O-K\n",
      "Word: tree -> Phonemes: T-R-E\n",
      "\n",
      "Word: cat -> Phonemes: S-A-T -> Durations (ms): [50, 100, 70]\n",
      "Word: apple -> Phonemes: A-P-L-E -> Durations (ms): [100, 50, 50, 120]\n",
      "Word: hello -> Phonemes: H-E-L-O -> Durations (ms): [50, 100, 50, 120]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    words1 = [\"cat\", \"cent\", \"apple\", \"the\", \"book\", \"tree\"]\n",
    "    for w in words1:\n",
    "        phonemes = simple_g2p(w)\n",
    "        print(f\"Word: {w} -> Phonemes: {'-'.join(phonemes)}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    words2 = [\"cat\", \"apple\", \"hello\"]\n",
    "    for w in words2:\n",
    "        phonemes, durs = simple_g2p_with_duration(w)\n",
    "        print(f\"Word: {w} -> Phonemes: {'-'.join(phonemes)} -> Durations (ms): {durs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc6e9d",
   "metadata": {},
   "source": [
    "# Cell 4: G2P Mapping Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ced45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DH', 'R', 'EH', 'SH', 'OW', 'L', 'D']\n"
     ]
    }
   ],
   "source": [
    "# A standalone grapheme→phoneme map for single letters and common digraphs\n",
    "g2p_map = {\n",
    "    'a': 'AH', 'b': 'B',  'c': 'K',  'd': 'D',\n",
    "    'e': 'EH','f': 'F',  'g': 'G',  'h': 'HH',\n",
    "    'i': 'IH','j': 'JH', 'k': 'K',  'l': 'L',\n",
    "    'm': 'M', 'n': 'N',  'o': 'OW', 'p': 'P',\n",
    "    'q': 'K', 'r': 'R',  's': 'S',  't': 'T',\n",
    "    'u': 'UH','v': 'V',  'w': 'W',  'x': 'K S',\n",
    "    'y': 'Y', 'z': 'Z',\n",
    "    'th': 'DH','sh': 'SH','ch': 'CH','ng': 'NG',\n",
    "    'ee': 'IY','oo': 'UW'\n",
    "}\n",
    "\n",
    "def map_word_to_phonemes(word, mapping):\n",
    "    \"\"\"\n",
    "    Apply a simple dictionary lookup (with longest-match first) \n",
    "    to convert word → phoneme list.\n",
    "    \"\"\"\n",
    "    w = word.lower()\n",
    "    phonemes = []\n",
    "    i = 0\n",
    "    while i < len(w):\n",
    "        # try two‑char digraph\n",
    "        if i < len(w)-1 and w[i:i+2] in mapping:\n",
    "            phonemes.append(mapping[w[i:i+2]])\n",
    "            i += 2\n",
    "        else:\n",
    "            phonemes.append(mapping.get(w[i], w[i].upper()))\n",
    "            i += 1\n",
    "    return phonemes\n",
    "\n",
    "# Example:\n",
    "print(map_word_to_phonemes(\"threshold\", g2p_map))  # ['TH','R','EH','SH','OW','L','D']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9416c9",
   "metadata": {},
   "source": [
    "# Cell 5: Extract Acoustic Features (duration, pitch, loudness, prosodic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d6ae209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ozair\\AppData\\Local\\Temp\\ipykernel_9832\\3189275010.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audio_path, sr=None)\n",
      "E:\\anaconda\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_audio.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mSoundFile(path)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'path_to_audio.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Replace with your file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_audio.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_path, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Duration (s)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m duration \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mget_duration(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\librosa\\core\\audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\librosa\\core\\audio.py:240\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    237\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     reader \u001b[38;5;241m=\u001b[39m audioread\u001b[38;5;241m.\u001b[39maudio_open(path)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    243\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m BackendClass(path)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_audio.wav'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Replace with your file\n",
    "audio_path = 'path_to_audio.wav'\n",
    "y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "# Duration (s)\n",
    "duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "# Pitch (F0) via PYIN\n",
    "f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "    y, \n",
    "    fmin=librosa.note_to_hz('C2'), \n",
    "    fmax=librosa.note_to_hz('C7')\n",
    ")\n",
    "mean_pitch = np.nanmean(f0)\n",
    "\n",
    "# Loudness (RMS energy)\n",
    "rms = librosa.feature.rms(y=y)[0]\n",
    "mean_loudness = np.mean(rms)\n",
    "\n",
    "# Prosodic proxy: Tempo (beats per minute)\n",
    "onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "\n",
    "features = {\n",
    "    'duration_s': duration,\n",
    "    'mean_pitch_hz': mean_pitch,\n",
    "    'mean_loudness_rms': mean_loudness,\n",
    "    'tempo_bpm': tempo\n",
    "}\n",
    "\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0080a13b",
   "metadata": {},
   "source": [
    "# Cell 6: Visualize Pitch & Loudness Over Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0c881f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Pitch contour\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m times \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mtimes_like(f0, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(times, f0, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f0' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pitch contour\n",
    "times = librosa.times_like(f0, sr=sr)\n",
    "plt.figure()\n",
    "plt.plot(times, f0, label='F0')\n",
    "plt.title('Pitch Contour')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# RMS loudness\n",
    "times_rms = librosa.frames_to_time(np.arange(len(rms)), sr=sr)\n",
    "plt.figure()\n",
    "plt.plot(times_rms, rms, label='RMS')\n",
    "plt.title('Loudness (RMS)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d32a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
